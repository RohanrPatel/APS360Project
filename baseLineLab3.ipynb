{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6WDvajSqIDs"
      },
      "source": [
        "# Lab 3: Gesture Recognition using Convolutional Neural Networks\n",
        "\n",
        "In this lab you will train a convolutional neural network to make classifications on different hand gestures. By the end of the lab, you should be able to:\n",
        "\n",
        "1. Load and split data for training, validation and testing\n",
        "2. Train a Convolutional Neural Network\n",
        "3. Apply transfer learning to improve your model\n",
        "\n",
        "Note that for this lab we will not be providing you with any starter code. You should be able to take the code used in previous labs, tutorials and lectures and modify it accordingly to complete the tasks outlined below.\n",
        "\n",
        "### What to submit\n",
        "\n",
        "Submit a PDF file containing all your code, outputs, and write-up\n",
        "from parts 1-5. You can produce a PDF of your Google Colab file by\n",
        "going to **File > Print** and then save as PDF. The Colab instructions\n",
        "has more information. Make sure to review the PDF submission to ensure that your answers are easy to read. Make sure that your text is not cut off at the margins. \n",
        "\n",
        "**Do not submit any other files produced by your code.**\n",
        "\n",
        "Include a link to your colab file in your submission.\n",
        "\n",
        "Please use Google Colab to complete this assignment. If you want to use Jupyter Notebook, please complete the assignment and upload your Jupyter Notebook file to Google Colab for submission. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfiFE_WOqIDu"
      },
      "source": [
        "## Colab Link\n",
        "\n",
        "Include a link to your colab file here\n",
        "\n",
        "Colab Link: https://colab.research.google.com/drive/1n7wklnqsOe1IuW6JVJzMEJuXe708yqwA?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvTXpH_kqIDy"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "American Sign Language (ASL) is a complete, complex language that employs signs made by moving the\n",
        "hands combined with facial expressions and postures of the body. It is the primary language of many\n",
        "North Americans who are deaf and is one of several communication options used by people who are deaf or\n",
        "hard-of-hearing. The hand gestures representing English alphabet are shown below. This lab focuses on classifying a subset\n",
        "of these hand gesture images using convolutional neural networks. Specifically, given an image of a hand\n",
        "showing one of the letters A-I, we want to detect which letter is being represented.\n",
        "\n",
        "![alt text](https://www.disabled-world.com/pics/1/asl-alphabet.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJxMgWGNqID2"
      },
      "source": [
        "## Part B. Building a CNN [50 pt]\n",
        "\n",
        "For this lab, we are not going to give you any starter code. You will be writing a convolutional neural network\n",
        "from scratch. You are welcome to use any code from previous labs, lectures and tutorials. You should also\n",
        "write your own code.\n",
        "\n",
        "You may use the PyTorch documentation freely. You might also find online tutorials helpful. However, all\n",
        "code that you submit must be your own.\n",
        "\n",
        "Make sure that your code is vectorized, and does not contain obvious inefficiencies (for example, unecessary\n",
        "for loops, or unnecessary calls to unsqueeze()). Ensure enough comments are included in the code so that\n",
        "your TA can understand what you are doing. It is your responsibility to show that you understand what you\n",
        "write.\n",
        "\n",
        "**This is much more challenging and time-consuming than the previous labs.** Make sure that you\n",
        "give yourself plenty of time by starting early."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiDuQaAh56sT"
      },
      "source": [
        "### 1. Data Loading and Splitting [5 pt]\n",
        "\n",
        "Download the anonymized data provided on Quercus. To allow you to get a heads start on this project we will provide you with sample data from previous years. Split the data into training, validation, and test sets.\n",
        "\n",
        "Note: Data splitting is not as trivial in this lab. We want our test set to closely resemble the setting in which\n",
        "our model will be used. In particular, our test set should contain hands that are never seen in training!\n",
        "\n",
        "Explain how you split the data, either by describing what you did, or by showing the code that you used.\n",
        "Justify your choice of splitting strategy. How many training, validation, and test images do you have?\n",
        "\n",
        "For loading the data, you can use plt.imread as in Lab 1, or any other method that you choose. You may find\n",
        "torchvision.datasets.ImageFolder helpful. (see https://pytorch.org/docs/stable/torchvision/datasets.html?highlight=image%20folder#torchvision.datasets.ImageFolder\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WBrH5kBqRLa6",
        "outputId": "e97a5952-9bb0-48ab-bb21-1cd9a3693692"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX5oqJ1bB9F8",
        "outputId": "2e947b61-fad9-4940-9d12-a74c54af1b78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'APS360-Pokemon-Data'...\n",
            "remote: Enumerating objects: 40741, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 40741 (delta 5), reused 14 (delta 2), pack-reused 40724\u001b[K\n",
            "Receiving objects: 100% (40741/40741), 736.35 MiB | 16.78 MiB/s, done.\n",
            "Resolving deltas: 100% (958/958), done.\n",
            "Checking out files: 100% (48377/48377), done.\n",
            "Total time elapsed: 52.94 seconds\n"
          ]
        }
      ],
      "source": [
        "# So it is pretty much impossible to share datasets over google drive unless you have a shared drive\n",
        "# But Colab lets you directly clone git repos, so just run this block\n",
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "!git clone https://github.com/Sidd-T/APS360-Pokemon-Data.git\n",
        "\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "\n",
        "#After this the files should be in the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AdEr6J86B-fp"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XbFJFN2CABW"
      },
      "outputs": [],
      "source": [
        "pokemon_ordered = pd.read_csv('/content/APS360-Pokemon-Data/labelled_set/pokemon.csv')\n",
        "pokemon_ordered = pokemon_ordered[[\"Name\", \"Type1\", \"Type2\"]]\n",
        "pokemon_t1 = pd.read_csv('/content/APS360-Pokemon-Data/labelled_set/pokemon_by_primary_type.csv')\n",
        "pokemon_t2 = pd.read_csv('/content/APS360-Pokemon-Data/labelled_set/pokemon_with_secondary_type_sorted.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "rfJAygDbCBaQ",
        "outputId": "b5568363-f4be-43c9-e983-a5583fa65c7d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b010a2bd-8ce1-469c-a0fd-2a3826f584f4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>img_path</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>staryu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>regirock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>deino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>luxio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>morelull</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>cubchoo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>ambipom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>frillish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>buizel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b010a2bd-8ce1-469c-a0fd-2a3826f584f4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b010a2bd-8ce1-469c-a0fd-2a3826f584f4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b010a2bd-8ce1-469c-a0fd-2a3826f584f4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            img_path      Name\n",
              "0  /content/APS360-Pokemon-Data/labelled_set/imag...    staryu\n",
              "1  /content/APS360-Pokemon-Data/labelled_set/imag...  regirock\n",
              "2  /content/APS360-Pokemon-Data/labelled_set/imag...     deino\n",
              "3  /content/APS360-Pokemon-Data/labelled_set/imag...     luxio\n",
              "4  /content/APS360-Pokemon-Data/labelled_set/imag...  morelull\n",
              "5  /content/APS360-Pokemon-Data/labelled_set/imag...   cubchoo\n",
              "6  /content/APS360-Pokemon-Data/labelled_set/imag...   ambipom\n",
              "7  /content/APS360-Pokemon-Data/labelled_set/imag...  frillish\n",
              "8  /content/APS360-Pokemon-Data/labelled_set/imag...    buizel"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "catcols = [\"Bug\", \"Dark\", \"Dragon\", \"Electric\", \"Fairy\", \"Fighting\", \"Fire\", \"Flying\", \"Ghost\", \n",
        "           \"Grass\",\"Ground\", \"Ice\", \"Normal\", \"Poison\", \"Psychic\", \"Rock\", \"Steel\", \"Water\"]\n",
        "\n",
        "img_path = []\n",
        "names = []\n",
        "\n",
        "IMG_DIR = '/content/APS360-Pokemon-Data/labelled_set/images'\n",
        "\n",
        "files = [f for f in listdir(IMG_DIR) if isfile(join(IMG_DIR, f))]\n",
        "for img in files:\n",
        "    pokemon_name = img.split('.')\n",
        "    path = IMG_DIR +'/' +str(img)\n",
        "    img_path.append(path)\n",
        "    names.append(pokemon_name[0])\n",
        "\n",
        "img_df = pd.DataFrame([])\n",
        "img_df['img_path'] = img_path\n",
        "img_df['Name'] = names\n",
        "\n",
        "img_df[:9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "URba0vn1CC5q",
        "outputId": "a0db88ba-0369-406d-c0d7-45d37eb2bb9d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-94af4160-79d9-41f4-b51a-b93c988cf5bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>type_num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>/content/APS360-Pokemon-Data/labelled_set/imag...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94af4160-79d9-41f4-b51a-b93c988cf5bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-94af4160-79d9-41f4-b51a-b93c988cf5bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-94af4160-79d9-41f4-b51a-b93c988cf5bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               image  type_num\n",
              "0  /content/APS360-Pokemon-Data/labelled_set/imag...         9\n",
              "1  /content/APS360-Pokemon-Data/labelled_set/imag...         9\n",
              "2  /content/APS360-Pokemon-Data/labelled_set/imag...         9\n",
              "3  /content/APS360-Pokemon-Data/labelled_set/imag...         6\n",
              "4  /content/APS360-Pokemon-Data/labelled_set/imag...         6\n",
              "5  /content/APS360-Pokemon-Data/labelled_set/imag...         6\n",
              "6  /content/APS360-Pokemon-Data/labelled_set/imag...        17\n",
              "7  /content/APS360-Pokemon-Data/labelled_set/imag...        17\n",
              "8  /content/APS360-Pokemon-Data/labelled_set/imag...        17"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type_num = []\n",
        "image = []\n",
        "\n",
        "for i, row in pokemon_ordered.iterrows():\n",
        "  type_num.append(catcols.index(row[\"Type1\"]))\n",
        "  for j, row2 in img_df.iterrows():\n",
        "    if row[\"Name\"] == row2[\"Name\"]:\n",
        "      path = row2[\"img_path\"]\n",
        "      break\n",
        "    else:\n",
        "      continue\n",
        "  image.append(path)  \n",
        "\n",
        "pokemon_ordered[\"type_num\"] = type_num\n",
        "pokemon_ordered[\"image\"] = image\n",
        "\n",
        "sub_po = pokemon_ordered[[\"image\", \"type_num\"]]\n",
        "sub_po[:9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJFkPxWXCEr_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.mkdir('/content/APS360-Pokemon-Data/labels')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0cONRxTCF_l",
        "outputId": "3e9400d5-4262-459a-980c-1555e4113fcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/APS360-Pokemon-Data/labels/0\n",
            "/content/APS360-Pokemon-Data/labels/1\n",
            "/content/APS360-Pokemon-Data/labels/2\n",
            "/content/APS360-Pokemon-Data/labels/3\n",
            "/content/APS360-Pokemon-Data/labels/4\n",
            "/content/APS360-Pokemon-Data/labels/5\n",
            "/content/APS360-Pokemon-Data/labels/6\n",
            "/content/APS360-Pokemon-Data/labels/7\n",
            "/content/APS360-Pokemon-Data/labels/8\n",
            "/content/APS360-Pokemon-Data/labels/9\n",
            "/content/APS360-Pokemon-Data/labels/10\n",
            "/content/APS360-Pokemon-Data/labels/11\n",
            "/content/APS360-Pokemon-Data/labels/12\n",
            "/content/APS360-Pokemon-Data/labels/13\n",
            "/content/APS360-Pokemon-Data/labels/14\n",
            "/content/APS360-Pokemon-Data/labels/15\n",
            "/content/APS360-Pokemon-Data/labels/16\n",
            "/content/APS360-Pokemon-Data/labels/17\n"
          ]
        }
      ],
      "source": [
        "parent_path = '/content/APS360-Pokemon-Data/labels/'\n",
        "for i in range(18):\n",
        "  dir_path = parent_path + str(i)\n",
        "  print(dir_path)\n",
        "  os.mkdir(dir_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bO568KuCH63"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "for i, row in sub_po.iterrows():\n",
        "  src = row[\"image\"]\n",
        "  dest = '/content/APS360-Pokemon-Data/labels/' + str(row[\"type_num\"])\n",
        "  shutil.copy2(src, dest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-q1oJ5pEqPn"
      },
      "outputs": [],
      "source": [
        "def get_data_loader(batch_size, path='/content/APS360-Pokemon-Data/labels/'):\n",
        "    torch.manual_seed(0)\n",
        "    \n",
        "    # these are prerequisite for using googleNet, according to https://pytorch.org/hub/pytorch_vision_googlenet/\n",
        "    # challenge 1 (image small)\n",
        "    transform = transforms.Compose([\n",
        "      transforms.Resize(256),\n",
        "      transforms.CenterCrop(224),\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "      ])\n",
        "\n",
        "    fullset = torchvision.datasets.ImageFolder(root=path, transform=transform)\n",
        "\n",
        "    #from lab 2, 2/3 is training, 1/6 is test, 1/6 is val\n",
        "\n",
        "    trainSetSize = int(len(fullset) * 2 / 3)\n",
        "    valSetSize = int(len(fullset) * 1 / 6)\n",
        "    testSetSize = len(fullset) - trainSetSize - valSetSize\n",
        "\n",
        "    train_set, val_set, test_set = data.random_split(fullset, [trainSetSize, valSetSize, testSetSize])\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,num_workers=1)\n",
        "    val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size,num_workers=1)\n",
        "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size,num_workers=1)\n",
        "    # length of loader is how many batches the set was split into\n",
        "    return train_loader, val_loader, test_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VWX4DGY5gQE"
      },
      "source": [
        "### 2. Model Building and Sanity Checking [15 pt]\n",
        "\n",
        "### Part (a) Convolutional Network - 5 pt\n",
        "\n",
        "Build a convolutional neural network model that takes the (224x224 RGB) image as input, and predicts the gesture\n",
        "letter. Your model should be a subclass of nn.Module. Explain your choice of neural network architecture: how\n",
        "many layers did you choose? What types of layers did you use? Were they fully-connected or convolutional?\n",
        "What about other decisions like pooling layers, activation functions, number of channels / hidden units?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeDTj63moa06"
      },
      "outputs": [],
      "source": [
        "# helper functions\n",
        "# get_data_loader(batch_size) from above above\n",
        "\n",
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    path = \"/content/gdrive/MyDrive/Project/michaelBaseLineTesting/model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path\n",
        "\n",
        "def evaluate(net, loader, criterion):\n",
        "    total_loss = 0.0\n",
        "    total_corr = 0.0\n",
        "    total_epoch = 0\n",
        "    for i, data in enumerate(loader, 0):\n",
        "        inputs, labels = data\n",
        "        outputs = net(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        pred = outputs.max(1, keepdim=True)[1]\n",
        "        total_corr += pred.eq(labels.view_as(pred)).sum().item() # so this == 2 pytorch tensors element-wise\n",
        "        \n",
        "        total_epoch += len(labels)\n",
        "    acc = float(total_corr) / total_epoch\n",
        "    loss = float(total_loss) / (i + 1)\n",
        "    return acc, loss\n",
        "\n",
        "# Training Curve\n",
        "def plot_training_curve(path):\n",
        "    import matplotlib.pyplot as plt\n",
        "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path))\n",
        "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path))\n",
        "    train_loss = np.loadtxt(\"{}_train_loss.csv\".format(path))\n",
        "    val_loss = np.loadtxt(\"{}_val_loss.csv\".format(path))\n",
        "    plt.title(\"Train vs Validation Accuracy\")\n",
        "    n = len(train_acc) # number of epochs\n",
        "    plt.plot(range(1,n+1), train_acc, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "    plt.title(\"Train vs Validation Loss\")\n",
        "    plt.plot(range(1,n+1), train_loss, label=\"Train\")\n",
        "    plt.plot(range(1,n+1), val_loss, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "collapsed": true,
        "id": "2dtx1z5951fS",
        "outputId": "910e69c2-313d-4781-d4f7-61f4379ad215"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n224*224 (3ch) --> conv 1 --> 54*54 (5ch) ((224-12)/4 + 1) \\n54*54 (5ch) --> max pool --> 27*27 (5ch)\\n27*27 (5ch) --> conv 2 --> 12*12 (10ch) ((27 - 5)/2 + 1)\\n12*12 (10ch) --> max pool --> 6*6 (10ch)\\n6*6*10 = 360 input for fc1\\n'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The endoder has 2 convolution layers, each followed by a relu activation and then a max pooling layer. Then 2 fully connected layer for classifier\n",
        "# This inital design is based on large net from lab 2 since it was shown to work. \n",
        "\n",
        "class michaelNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(michaelNet, self).__init__()\n",
        "        self.name = \"michaelNet\"\n",
        "        self.conv1 = nn.Conv2d(3, 5, 12, 4) # 3 channel for RGB, 5 output channel, kernel = 12, stride 4\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 2*2 kernel, stride 2\n",
        "        self.conv2 = nn.Conv2d(5, 10, 5,2)\n",
        "        self.fc1 = nn.Linear(360, 32) # see justification for below\n",
        "        self.fc2 = nn.Linear(32, 9) # 32 hidden units is carried from large net, 9 output cuz classifying 9 letters\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 360)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        # x = x.squeeze(1) # Flatten to [batch_size]\n",
        "        return x\n",
        "\n",
        "\"\"\"\n",
        "224*224 (3ch) --> conv 1 --> 54*54 (5ch) ((224-12)/4 + 1) \n",
        "54*54 (5ch) --> max pool --> 27*27 (5ch)\n",
        "27*27 (5ch) --> conv 2 --> 12*12 (10ch) ((27 - 5)/2 + 1)\n",
        "12*12 (10ch) --> max pool --> 6*6 (10ch)\n",
        "6*6*10 = 360 input for fc1\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeGvelvb515e"
      },
      "source": [
        "### Part (b) Training Code - 5 pt\n",
        "\n",
        "Write code that trains your neural network given some training data. Your training code should make it easy\n",
        "to tweak the usual hyperparameters, like batch size, learning rate, and the model object itself. Make sure\n",
        "that you are checkpointing your models from time to time (the frequency is up to you). Explain your choice\n",
        "of loss function and optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "17YTQv4l54W1"
      },
      "outputs": [],
      "source": [
        "def train(model, batch_size=64, learning_rate=0.01, num_epochs=24):\n",
        "    torch.manual_seed(1000)\n",
        "\n",
        "    train_loader, val_loader, test_loader = get_data_loader(batch_size=batch_size)\n",
        "        \n",
        "    # now use cross entropy since it's not a binary choice.\n",
        "    # using SGD with momentum because SGD explores a lot of possibilty space, \n",
        "    # and momentum helps accelerate SGD in the relevant direction and dampens oscillations\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "\n",
        "    # arrays for keeping track of things\n",
        "    train_acc = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_acc = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "\n",
        "    # training\n",
        "    start_time = time.time()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_train_loss = 0.0\n",
        "        total_train_corr = 0.0\n",
        "        total_epoch = 0\n",
        "\n",
        "        i = 0\n",
        "        for imgs, labels in train_loader: # this for loop takes a long time to load all images in first iteration\n",
        "            #imgs, labels = data\n",
        "            #print(i)\n",
        "            # gradient descent\n",
        "            out = model(imgs)             # forward pass\n",
        "            loss = criterion(out, labels) # compute the total loss\n",
        "            loss.backward()               # backward pass (compute parameter updates)\n",
        "            optimizer.step()              # make the updates for each parameter\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # Calculate the statistics\n",
        "            total_train_loss += loss.item()\n",
        "            #print(len(out), out)\n",
        "            pred = out.max(1, keepdim=True)[1]\n",
        "            #print(pred)\n",
        "            total_train_corr += pred.eq(labels.view_as(pred)).sum().item()\n",
        "            total_epoch += len(labels)\n",
        "            i+=1\n",
        "            \n",
        "        train_acc[epoch] = float(total_train_corr) / total_epoch\n",
        "        train_loss[epoch] = float(total_train_loss) / (i+1)\n",
        "        val_acc[epoch], val_loss[epoch] = evaluate(model, val_loader, criterion)\n",
        "        print((\"Epoch {}: Train acc: {}, Train loss: {} | \"+\n",
        "               \"Validation Accuracy: {}, Validation loss: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_acc[epoch],\n",
        "                   train_loss[epoch],\n",
        "                   val_acc[epoch],\n",
        "                   val_loss[epoch]))\n",
        "        \n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = get_model_name(model.name, batch_size, learning_rate, epoch)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "  \n",
        "    print('Finished Training')\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
        "    \n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_acc)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
        "    np.savetxt(\"{}_val_acc.csv\".format(model_path), val_acc)\n",
        "    np.savetxt(\"{}_val_loss.csv\".format(model_path), val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvDLw-Vz6eVS"
      },
      "source": [
        "### 3. Hyperparameter Search [10 pt]\n",
        "\n",
        "### Part (a) - 1 pt\n",
        "\n",
        "List 3 hyperparameters that you think are most worth tuning. Choose at least one hyperparameter related to\n",
        "the model architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "HXRQbgMqR_Qy"
      },
      "outputs": [],
      "source": [
        "# batch size, learning rate, num_epochs, more layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeD6EzPB6kSW"
      },
      "source": [
        "### Part (b) - 5 pt\n",
        "\n",
        "Tune the hyperparameters you listed in Part (a), trying as many values as you need to until you feel satisfied\n",
        "that you are getting a good model. Plot the training curve of at least 4 different hyperparameter settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "GViOPPdgfRmx",
        "outputId": "6177176e-6fc4-4226-85fb-878cdf02d4e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n224*224 (3ch) --> conv 1 --> 54*54 (5ch) ((224-11)/3 + 1) \\n72*72 (5ch) --> max pool 1 --> 36*36 (5ch)\\n36*36 (5ch) --> conv 2 --> 17*17 (10ch) ((36 - 4)/2 + 1)\\n17*17 (10ch) --> conv 3 --> 15*15 (15ch) ((17-3) + 1)\\n15*15 (15ch) --> max pool 2 --> 7*7 (15ch) ((15-3)/2 + 1)\\n\\n7*7*15 for fc1\\n'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# now to increase depth to 3 convolution layer\n",
        "\n",
        "class michaelNetDeeper(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(michaelNetDeeper, self).__init__()\n",
        "        self.name = \"michaelNetDeeper\"\n",
        "        self.conv1 = nn.Conv2d(3, 5, 11, 3) # 3 channel for RGB, 5 output channel, kernel = 11, stride 3\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) # 2*2 kernel, stride 2\n",
        "        self.conv2 = nn.Conv2d(5, 10, 4, 2)\n",
        "        self.conv3 = nn.Conv2d(10, 15, 3)\n",
        "        self.pool2 = nn.MaxPool2d(3, 2)\n",
        "        self.fc1 = nn.Linear(7*7*15, 254) # see justification for below\n",
        "        self.fc2 = nn.Linear(254, 18) # 32 hidden units is carried from large net, 9 output cuz classifying 9 letters\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 7*7*15)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\"\"\"\n",
        "224*224 (3ch) --> conv 1 --> 54*54 (5ch) ((224-11)/3 + 1) \n",
        "72*72 (5ch) --> max pool 1 --> 36*36 (5ch)\n",
        "36*36 (5ch) --> conv 2 --> 17*17 (10ch) ((36 - 4)/2 + 1)\n",
        "17*17 (10ch) --> conv 3 --> 15*15 (15ch) ((17-3) + 1)\n",
        "15*15 (15ch) --> max pool 2 --> 7*7 (15ch) ((15-3)/2 + 1)\n",
        "\n",
        "7*7*15 for fc1\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM0xcSDGkn2G"
      },
      "outputs": [],
      "source": [
        "num_hidden_units = 32\n",
        "# max pooling, 4 con layers and 3 pooling layers, small change from the proposal\n",
        "# for better dimensions fed into the fc layers\n",
        "class baselineClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(baselineClassifier, self).__init__()\n",
        "        self.name = \"baselineModel\"\n",
        "        # RGB, output channels, kernel size,  stride \n",
        "        self.conv1 = nn.Conv2d(3, 5, 18, 2)\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 2*2 kernel, stride 2\n",
        "        self.conv2 = nn.Conv2d(5, 7, 11, 3)\n",
        "        self.conv3 = nn.Conv2d(7, 9, 5, 2)\n",
        "        self.conv4 = nn.Conv2d(9, 11, 3, 2)\n",
        "        # no pool4\n",
        "        self.fc1 = nn.Linear(176, num_hidden_units)\n",
        "        self.fc2 = nn.Linear(num_hidden_units, 18)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # print(x.shape)\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        # print(x.shape)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        # print(x.shape)\n",
        "        x = x.view(-1, 176)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "# NEED 18 AS FINAL OUTPUT FROM FC2 DUE TO 18 POKEMON TYPES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kjijVdlQlLaF",
        "outputId": "b8a8633f-389c-443b-8da0-1288a4ee1635"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e76dd1de49d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmyNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaselineClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-42f94e49e762>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, batch_size, learning_rate, num_epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# gradient descent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m             \u001b[0;31m# forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute the total loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m               \u001b[0;31m# backward pass (compute parameter updates)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-91b0406a0a30>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m176\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    453\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 454\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1 x 1). Kernel size: (3 x 3). Kernel size can't be greater than actual input size"
          ]
        }
      ],
      "source": [
        "myNet = baselineClassifier()\n",
        "train(myNet, batch_size = 32, num_epochs = 36, learning_rate = 0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "UkvdR-cB6nzm"
      },
      "outputs": [],
      "source": [
        "myNet = michaelNetDeeper()\n",
        "train(myNet, batch_size = 32, num_epochs = 36, learning_rate = 0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "CTi1baNOtpio",
        "outputId": "592cc8dc-ad37-4bdd-c06b-feb17d9761bc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_path = get_model_name(\"michaelNetDeeper\", batch_size = 32, epoch = 35, learning_rate=0.005)\n",
        "plot_training_curve(model_path)\n",
        "\n",
        "# best at Epoch 31: Train acc: 0.9722972972972973, Train loss: 0.07138941824436187 | Validation Accuracy: 0.8540540540540541, Validation loss: 0.6777972479661306"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqFZO5eprjtT"
      },
      "outputs": [],
      "source": [
        "model_path = get_model_name(\"michaelNetDeeper\", batch_size = 32, epoch = 35, learning_rate=0.005)\n",
        "plot_training_curve(model_path)\n",
        "# best at Epoch 30: Train acc: 0.9905405405405405, Train loss: 0.02819463643512184 | Validation Accuracy: 0.8891891891891892, Validation loss: 0.7493736160298189"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzNA5oup67JO"
      },
      "source": [
        "### Part (d) - 2 pt\n",
        "Report the test accuracy of your best model. You should only do this step once and prior to this step you should have only used the training and validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2eJ7AbVl6-ax",
        "outputId": "37057fdf-dd47-45f6-9502-9ba9dc4c22f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy is 0.08823529411764706 Test loss is 3.343052291870117\n"
          ]
        }
      ],
      "source": [
        "bestMichael = michaelNetDeeper()\n",
        "model_path = get_model_name(\"michaelNetDeeper\", batch_size = 32, epoch = 14, learning_rate = 0.005)\n",
        "state = torch.load(model_path)\n",
        "bestMichael.load_state_dict(state)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "train_loader, val_loader, test_loader = get_data_loader(batch_size=32)\n",
        "test_acc, test_loss = evaluate(bestMichael, test_loader, criterion)\n",
        "\n",
        "\n",
        "print(\"Test accuracy is\", test_acc, \"Test loss is\", test_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYLJ_VoNI6fO",
        "outputId": "50592b25-839f-4aef-d192-8d0474409ced"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.7.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.7.1\n"
          ]
        }
      ],
      "source": [
        "pip install torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv6DzcpIIz_P",
        "outputId": "0a7aaa2b-8ae3-46d7-de02-e20e1ca84467"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "michaelNetDeeper                         [1, 18]                   --\n",
              "├─Conv2d: 1-1                            [5, 78, 78]               1,820\n",
              "├─MaxPool2d: 1-2                         [5, 39, 39]               --\n",
              "├─Conv2d: 1-3                            [10, 18, 18]              810\n",
              "├─Conv2d: 1-4                            [15, 16, 16]              1,365\n",
              "├─MaxPool2d: 1-5                         [15, 7, 7]                --\n",
              "├─Linear: 1-6                            [1, 254]                  186,944\n",
              "├─Linear: 1-7                            [1, 18]                   4,590\n",
              "==========================================================================================\n",
              "Total params: 195,529\n",
              "Trainable params: 195,529\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 1.37\n",
              "==========================================================================================\n",
              "Input size (MB): 0.71\n",
              "Forward/backward pass size (MB): 0.30\n",
              "Params size (MB): 0.78\n",
              "Estimated Total Size (MB): 1.80\n",
              "=========================================================================================="
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torchinfo\n",
        "\n",
        "myModel = michaelNetDeeper()\n",
        "torchinfo.summary(myModel, (3, 244, 244))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "bk1RNgAj54rZ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}